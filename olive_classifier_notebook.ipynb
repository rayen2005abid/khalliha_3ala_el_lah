{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import"
      ],
      "metadata": {
        "id": "NOIUBrUvTBjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import EfficientNetLiteB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Configuration parameters\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "MODEL_PATH = 'olive_model.h5'\n",
        "DATASET_PATH = 'augmented_images/'\n"
      ],
      "metadata": {
        "id": "ajhMLcyRAwCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "dab54092-1c37-4a32-b8f4-d1317e4b8a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'EfficientNetLiteB0' from 'tensorflow.keras.applications' (/usr/local/lib/python3.11/dist-packages/keras/_tf_keras/keras/applications/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7dd1fc49c0f9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientNetLiteB0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'EfficientNetLiteB0' from 'tensorflow.keras.applications' (/usr/local/lib/python3.11/dist-packages/keras/_tf_keras/keras/applications/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Import & Dataset Setup"
      ],
      "metadata": {
        "id": "DqyXusb1TU4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"original_images/\"\n",
        "output_folder = \"augmented_images/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "rub-RnYsTVmg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "c820c449-5cbf-4a99-ea3a-748b057a38d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e63c52aea1f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"original_images/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"augmented_images/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "augmentation"
      ],
      "metadata": {
        "id": "1V_ujDLRBSFB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zs1ntq_kVpj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Albumentations pipeline for augmentation\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Rotate(limit=20, p=0.5),\n",
        "    A.GaussianBlur(p=0.2)\n",
        "])\n",
        "\n",
        "# Apply augmentation to images\n",
        "for img_name in os.listdir(input_folder):\n",
        "    img_path = os.path.join(input_folder, img_name)\n",
        "    image = np.array(Image.open(img_path).convert('RGB'))  # Ensure 3 channels\n",
        "    for i in range(5):  # 5 augmentations per image\n",
        "        augmented = transform(image=image)['image']\n",
        "        Image.fromarray(augmented).save(f\"{output_folder}/{img_name[:-4]}_aug{i}.jpg\")"
      ],
      "metadata": {
        "id": "UcUYHREkB0CC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "ad809c6e-ad0d-4545-958f-c517301ed3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'original_images/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-43bea4bc4f94>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Apply augmentation to images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure 3 channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'original_images/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Setup & Training"
      ],
      "metadata": {
        "id": "jc3KL_8STitk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import time\n",
        "import json\n",
        "\n",
        "class OliveClassifierEfficientNet:\n",
        "    def __init__(self, img_height=224, img_width=224, batch_size=32):\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.model = None\n",
        "        self.class_names = None\n",
        "        self.history = None\n",
        "        self.model_name = \"EfficientNet-Lite0\"\n",
        "\n",
        "    def build_model(self, num_classes):\n",
        "        \"\"\"Build EfficientNet-Lite B0 model for olive classification\"\"\"\n",
        "        # Import EfficientNet-Lite0 model\n",
        "        try:\n",
        "            # Using TF-Hub approach\n",
        "            import tensorflow_hub as hub\n",
        "            base_model = hub.KerasLayer(\n",
        "                \"https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2\",\n",
        "                trainable=False\n",
        "            )\n",
        "\n",
        "            # Create new model with EfficientNet-Lite0 as base\n",
        "            inputs = tf.keras.Input(shape=(self.img_height, self.img_width, 3))\n",
        "            x = base_model(inputs)\n",
        "            x = layers.Dropout(0.2)(x)\n",
        "            x = layers.Dense(128, activation='relu')(x)\n",
        "            x = layers.Dropout(0.2)(x)\n",
        "            outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "            model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        except:\n",
        "            # Fallback to EfficientNetB0 from Keras applications if TF-Hub import fails\n",
        "            print(\"Falling back to EfficientNetB0 from Keras applications\")\n",
        "            from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "            base_model = EfficientNetB0(\n",
        "                weights='imagenet',\n",
        "                include_top=False,\n",
        "                input_shape=(self.img_height, self.img_width, 3)\n",
        "            )\n",
        "\n",
        "            # Freeze the base model layers\n",
        "            base_model.trainable = False\n",
        "\n",
        "            # Create new model\n",
        "            model = models.Sequential([\n",
        "                base_model,\n",
        "                layers.GlobalAveragePooling2D(),\n",
        "                layers.Dropout(0.2),\n",
        "                layers.Dense(128, activation='relu'),\n",
        "                layers.Dropout(0.2),\n",
        "                layers.Dense(num_classes, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            self.model_name = \"EfficientNetB0\"\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(\n",
        "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "        return model\n",
        "\n",
        "    def create_data_generators(self, data_dir):\n",
        "        \"\"\"Create data generators for training, validation, and test sets\"\"\"\n",
        "        # Create training data generator with augmentation\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            fill_mode='nearest',\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        # Create test data generator without augmentation\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "        # Create training and validation generators\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='training',\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        validation_generator = train_datagen.flow_from_directory(\n",
        "            data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='validation',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        # If test_dir is provided, create test generator\n",
        "        test_dir = os.path.join(os.path.dirname(data_dir), 'test')\n",
        "        if os.path.exists(test_dir):\n",
        "            test_generator = test_datagen.flow_from_directory(\n",
        "                test_dir,\n",
        "                target_size=(self.img_height, self.img_width),\n",
        "                batch_size=self.batch_size,\n",
        "                class_mode='categorical',\n",
        "                shuffle=False\n",
        "            )\n",
        "        else:\n",
        "            test_generator = validation_generator\n",
        "\n",
        "        # Save class names\n",
        "        self.class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "        return train_generator, validation_generator, test_generator\n",
        "\n",
        "    def train(self, train_generator, validation_generator, epochs=15, callbacks=None):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        if callbacks is None:\n",
        "            # Define callbacks for model training\n",
        "            callbacks = [\n",
        "                tf.keras.callbacks.EarlyStopping(\n",
        "                    monitor='val_loss',\n",
        "                    patience=5,\n",
        "                    restore_best_weights=True\n",
        "                ),\n",
        "                tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                    monitor='val_loss',\n",
        "                    factor=0.2,\n",
        "                    patience=3,\n",
        "                    min_lr=0.00001\n",
        "                )\n",
        "            ]\n",
        "\n",
        "        # Start timing\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "\n",
        "        # Calculate training time\n",
        "        training_time = time.time() - start_time\n",
        "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "        self.history = history\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, test_generator):\n",
        "        \"\"\"Evaluate the model\"\"\"\n",
        "        # Evaluate the model\n",
        "        test_loss, test_accuracy = self.model.evaluate(test_generator)\n",
        "        print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"Test loss: {test_loss:.4f}\")\n",
        "\n",
        "        # Get predictions for confusion matrix\n",
        "        steps = test_generator.samples // test_generator.batch_size + 1\n",
        "        predictions = self.model.predict(test_generator, steps=steps)\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "        y_true = test_generator.classes[:len(y_pred)]  # Match length of predictions\n",
        "\n",
        "        # Print classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        report = classification_report(y_true, y_pred, target_names=self.class_names, output_dict=True)\n",
        "        print(classification_report(y_true, y_pred, target_names=self.class_names))\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.class_names, yticklabels=self.class_names)\n",
        "        plt.title(f'Confusion Matrix - {self.model_name}')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix.png')\n",
        "        plt.show()\n",
        "\n",
        "        return {\n",
        "            'accuracy': test_accuracy,\n",
        "            'loss': test_loss,\n",
        "            'classification_report': report,\n",
        "            'confusion_matrix': cm.tolist()\n",
        "        }\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"Plot training and validation accuracy and loss\"\"\"\n",
        "        acc = self.history.history['accuracy']\n",
        "        val_acc = self.history.history['val_accuracy']\n",
        "        loss = self.history.history['loss']\n",
        "        val_loss = self.history.history['val_loss']\n",
        "\n",
        "        epochs_range = range(len(acc))\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs_range, loss, label='Training Loss')\n",
        "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_history.png')\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the model and metadata\"\"\"\n",
        "        # Create directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)\n",
        "\n",
        "        # Save the model\n",
        "        self.model.save(filepath)\n",
        "\n",
        "        # Save class names and metadata\n",
        "        metadata = {\n",
        "            'class_names': self.class_names,\n",
        "            'img_height': self.img_height,\n",
        "            'img_width': self.img_width,\n",
        "            'model_name': self.model_name,\n",
        "            'date_created': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        }\n",
        "\n",
        "        with open(f\"{filepath}_metadata.json\", \"w\") as f:\n",
        "            json.dump(metadata, f)\n",
        "\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load a saved model and metadata\"\"\"\n",
        "        # Load the model\n",
        "        self.model = models.load_model(filepath, compile=True)\n",
        "\n",
        "        # Load metadata\n",
        "        try:\n",
        "            with open(f\"{filepath}_metadata.json\", \"r\") as f:\n",
        "                metadata = json.load(f)\n",
        "                self.class_names = metadata['class_names']\n",
        "                self.img_height = metadata['img_height']\n",
        "                self.img_width = metadata['img_width']\n",
        "                self.model_name = metadata.get('model_name', 'EfficientNet-Lite0')\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: Metadata file not found. Class names may not be available.\")\n",
        "\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "\n",
        "    def predict_image(self, image_path):\n",
        "        \"\"\"Predict the class of a single image\"\"\"\n",
        "        # Check if image exists\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Error: Image file '{image_path}' not found.\")\n",
        "            return None\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = tf.keras.preprocessing.image.load_img(\n",
        "            image_path, target_size=(self.img_height, self.img_width)\n",
        "        )\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = tf.expand_dims(img_array, 0) / 255.0\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = self.model.predict(img_array)\n",
        "        predicted_class_index = np.argmax(predictions[0])\n",
        "\n",
        "        # Check if class names are available\n",
        "        if self.class_names:\n",
        "            predicted_class = self.class_names[predicted_class_index]\n",
        "        else:\n",
        "            predicted_class = f\"Class {predicted_class_index}\"\n",
        "\n",
        "        confidence = float(predictions[0][predicted_class_index])\n",
        "\n",
        "        # Display results\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Predicted: {predicted_class} ({confidence:.2%})\")\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Create result dictionary with all classes and probabilities\n",
        "        results = {}\n",
        "        if self.class_names:\n",
        "            results = {self.class_names[i]: float(predictions[0][i]) for i in range(len(self.class_names))}\n",
        "        else:\n",
        "            results = {f\"Class {i}\": float(predictions[0][i]) for i in range(len(predictions[0]))}\n",
        "\n",
        "        return {\n",
        "            'predicted_class': predicted_class,\n",
        "            'confidence': confidence,\n",
        "            'all_probabilities': results,\n",
        "            'image_path': image_path\n",
        "        }\n",
        "\n",
        "    def predict_batch(self, image_dir):\n",
        "        \"\"\"Predict classes for all images in a directory\"\"\"\n",
        "        # Check if directory exists\n",
        "        if not os.path.exists(image_dir):\n",
        "            print(f\"Error: Directory '{image_dir}' not found.\")\n",
        "            return None\n",
        "\n",
        "        # Get all image files\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
        "        image_files = [\n",
        "            os.path.join(image_dir, f) for f in os.listdir(image_dir)\n",
        "            if os.path.splitext(f.lower())[1] in image_extensions\n",
        "        ]\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"No image files found in '{image_dir}'\")\n",
        "            return None\n",
        "\n",
        "        # Predict each image\n",
        "        results = []\n",
        "        for image_path in image_files:\n",
        "            print(f\"Predicting {os.path.basename(image_path)}...\")\n",
        "            result = self.predict_image(image_path)\n",
        "            if result:\n",
        "                results.append(result)\n",
        "\n",
        "        # Summarize results\n",
        "        print(f\"\\nPredicted {len(results)} images\")\n",
        "\n",
        "        return results\n",
        "\n",
        "# Example notebook usage\n",
        "def run_notebook_example():\n",
        "    # Replace these values with your own settings\n",
        "    data_dir = \"olive_images\"  # Path to your training data\n",
        "    model_path = \"models/olive_classifier\"  # Where to save the model\n",
        "    epochs = 15\n",
        "    batch_size = 32\n",
        "\n",
        "    # Create classifier\n",
        "    classifier = OliveClassifierEfficientNet(img_height=224, img_width=224, batch_size=batch_size)\n",
        "\n",
        "    # Dataset creation and training\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Loading existing model from {model_path}...\")\n",
        "        classifier.load_model(model_path)\n",
        "    elif os.path.exists(data_dir):\n",
        "        print(f\"Training new model with data from {data_dir}...\")\n",
        "        # Create data generators\n",
        "        train_generator, validation_generator, test_generator = classifier.create_data_generators(data_dir)\n",
        "\n",
        "        # Build model\n",
        "        num_classes = len(train_generator.class_indices)\n",
        "        print(f\"Found {num_classes} olive classes: {list(train_generator.class_indices.keys())}\")\n",
        "        classifier.build_model(num_classes)\n",
        "\n",
        "        # Print model summary\n",
        "        classifier.model.summary()\n",
        "\n",
        "        # Train model\n",
        "        classifier.train(train_generator, validation_generator, epochs=epochs)\n",
        "\n",
        "        # Plot training history\n",
        "        classifier.plot_training_history()\n",
        "\n",
        "        # Evaluate model\n",
        "        eval_results = classifier.evaluate(test_generator)\n",
        "\n",
        "        # Save model\n",
        "        os.makedirs(os.path.dirname(model_path) if os.path.dirname(model_path) else '.', exist_ok=True)\n",
        "        classifier.save_model(model_path)\n",
        "    else:\n",
        "        print(f\"Error: Neither model path {model_path} nor data directory {data_dir} exists.\")\n",
        "        return\n",
        "\n",
        "    # Return the classifier for further use\n",
        "    return classifier\n",
        "\n",
        "# This is what you'll run in your notebook\n",
        "# classifier = run_notebook_example()\n",
        "\n",
        "# To predict a single image:\n",
        "# result = classifier.predict_image(\"path/to/your/olive_image.jpg\")\n",
        "\n",
        "# To predict multiple images in a directory:\n",
        "# results = classifier.predict_batch(\"path/to/your/test_images\")"
      ],
      "metadata": {
        "id": "b-ofCiINTjGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# retrieve data from the ship"
      ],
      "metadata": {
        "id": "kebqvaSfH24L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MicroPython Code (ESP32)\n",
        "from umqtt.simple import MQTTClient\n",
        "import ujson\n",
        "from machine import UART\n",
        "\n",
        "# OBD-II UART Setup\n",
        "obd = UART(1, baudrate=9600, tx=17, rx=16)\n",
        "\n",
        "# MQTT Setup\n",
        "client = MQTTClient(\"car_123\", \"mqtt.broker.com\")\n",
        "client.connect()\n",
        "\n",
        "while True:\n",
        "    # Read OBD-II data (e.g., RPM)\n",
        "    obd.write(\"010C\\r\\n\")  # RPM PID\n",
        "    response = obd.read()\n",
        "\n",
        "    # Publish to MQTT\n",
        "    payload = ujson.dumps({\"rpm\": response})\n",
        "    client.publish(\"car/123/obd\", payload)\n",
        "\n"
      ],
      "metadata": {
        "id": "_0jn74n3H3ZF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "c2b5527b-5bfa-483c-f0be-e1766d2dff64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'umqtt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-82bffb6f91af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# MicroPython Code (ESP32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mumqtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMQTTClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mujson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umqtt'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESP32-CAM (MicroPython code)"
      ],
      "metadata": {
        "id": "SrYLMDvpciWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import network\n",
        "import socket\n",
        "import time\n",
        "from machine import Pin\n",
        "import esp32\n",
        "import camera\n",
        "\n",
        "# Import configuration from separate file\n",
        "try:\n",
        "    import config\n",
        "    SSID = config.WIFI_SSID\n",
        "    PASSWORD = config.WIFI_PASSWORD\n",
        "    PC_IP = config.SERVER_IP\n",
        "    PC_PORT = config.SERVER_PORT\n",
        "except ImportError:\n",
        "    print(\"Config file not found. Please create config.py with your settings.\")\n",
        "    raise\n",
        "\n",
        "# === Connect to Wi-Fi ===\n",
        "def connect_wifi():\n",
        "    wlan = network.WLAN(network.STA_IF)\n",
        "    wlan.active(True)\n",
        "    wlan.connect(SSID, PASSWORD)\n",
        "    while not wlan.isconnected():\n",
        "        print('Connecting to WiFi...')\n",
        "        time.sleep(1)\n",
        "    print('Connected:', wlan.ifconfig())\n",
        "\n",
        "# === Camera Init ===\n",
        "def init_camera():\n",
        "    try:\n",
        "        camera.init(0, format=camera.JPEG)\n",
        "        camera.framesize(camera.FRAME_QVGA)  # Options: FRAME_QVGA, FRAME_VGA, etc.\n",
        "        print(\"Camera initialized\")\n",
        "    except Exception as e:\n",
        "        print(\"Camera init failed:\", e)\n",
        "\n",
        "# === Capture and Send ===\n",
        "def capture_and_send():\n",
        "    try:\n",
        "        img = camera.capture()\n",
        "        print(f\"Captured image: {len(img)} bytes\")\n",
        "\n",
        "        s = socket.socket()\n",
        "        s.connect((PC_IP, PC_PORT))\n",
        "        s.send(img)\n",
        "        s.close()\n",
        "        print(\"Image sent\")\n",
        "    except Exception as e:\n",
        "        print(\"Error sending image:\", e)\n",
        "\n",
        "# === Main ===\n",
        "try:\n",
        "    connect_wifi()\n",
        "    init_camera()\n",
        "\n",
        "    while True:\n",
        "        capture_and_send()\n",
        "        time.sleep(5)  # Send every 5 seconds\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Program stopped by user\")\n",
        "    camera.deinit()\n",
        "except Exception as e:\n",
        "    print(f\"Fatal error: {e}\")\n",
        "    camera.deinit()"
      ],
      "metadata": {
        "id": "XiaeGnsrceEF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "90d76a34-2bb2-4c33-9878-120a0738574d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'network'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ac42647d8c84>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# esp32_cam_send.py (MicroPython on ESP32-CAM)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'network'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PC (Python script to receive image)"
      ],
      "metadata": {
        "id": "UjKhqd8jcsjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pc_receiver.py (Python on your PC)\n",
        "import socket\n",
        "\n",
        "HOST = '0.0.0.0'\n",
        "PORT = 8080\n",
        "\n",
        "server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "server.bind((HOST, PORT))\n",
        "server.listen(1)\n",
        "\n",
        "print(f\"Listening on port {PORT}...\")\n",
        "\n",
        "img_counter = 0\n",
        "\n",
        "while True:\n",
        "    conn, addr = server.accept()\n",
        "    print(f\"Connection from {addr}\")\n",
        "\n",
        "    data = b''\n",
        "    while True:\n",
        "        chunk = conn.recv(4096)\n",
        "        if not chunk:\n",
        "            break\n",
        "        data += chunk\n",
        "\n",
        "    with open(f'image_{img_counter}.jpg', 'wb') as f:\n",
        "        f.write(data)\n",
        "        print(f'Saved image_{img_counter}.jpg')\n",
        "\n",
        "    img_counter += 1\n",
        "    conn.close()\n"
      ],
      "metadata": {
        "id": "yq_kjO7GcsDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "7836e7b0-af47-40a1-a9e2-a9e81383e7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 98] Address already in use",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-55c962d7ad49>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_INET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHOST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 98] Address already in use"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Recognition**\n"
      ],
      "metadata": {
        "id": "6NZ-CkG2qD1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import time\n",
        "import json\n",
        "\n",
        "class OliveClassifierEfficientNet:\n",
        "    def __init__(self, img_height=224, img_width=224, batch_size=32):\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        self.batch_size = batch_size\n",
        "        self.model = None\n",
        "        self.class_names = None\n",
        "        self.history = None\n",
        "        self.model_name = \"EfficientNet-Lite0\"\n",
        "\n",
        "    def build_model(self, num_classes):\n",
        "        \"\"\"Build EfficientNet-Lite B0 model for olive classification\"\"\"\n",
        "        # Import EfficientNet-Lite0 model\n",
        "        try:\n",
        "            # Using TF-Hub approach\n",
        "            import tensorflow_hub as hub\n",
        "            base_model = hub.KerasLayer(\n",
        "                \"https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2\",\n",
        "                trainable=False\n",
        "            )\n",
        "\n",
        "            # Create new model with EfficientNet-Lite0 as base\n",
        "            inputs = tf.keras.Input(shape=(self.img_height, self.img_width, 3))\n",
        "            x = base_model(inputs)\n",
        "            x = layers.Dropout(0.2)(x)\n",
        "            x = layers.Dense(128, activation='relu')(x)\n",
        "            x = layers.Dropout(0.2)(x)\n",
        "            outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "            model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        except:\n",
        "            # Fallback to EfficientNetB0 from Keras applications if TF-Hub import fails\n",
        "            print(\"Falling back to EfficientNetB0 from Keras applications\")\n",
        "            from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "            base_model = EfficientNetB0(\n",
        "                weights='imagenet',\n",
        "                include_top=False,\n",
        "                input_shape=(self.img_height, self.img_width, 3)\n",
        "            )\n",
        "\n",
        "            # Freeze the base model layers\n",
        "            base_model.trainable = False\n",
        "\n",
        "            # Create new model\n",
        "            model = models.Sequential([\n",
        "                base_model,\n",
        "                layers.GlobalAveragePooling2D(),\n",
        "                layers.Dropout(0.2),\n",
        "                layers.Dense(128, activation='relu'),\n",
        "                layers.Dropout(0.2),\n",
        "                layers.Dense(num_classes, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            self.model_name = \"EfficientNetB0\"\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(\n",
        "            optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "        return model\n",
        "\n",
        "    def create_data_generators(self, data_dir):\n",
        "        \"\"\"Create data generators for training, validation, and test sets\"\"\"\n",
        "        # Create training data generator with augmentation\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            fill_mode='nearest',\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        # Create test data generator without augmentation\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "        # Create training and validation generators\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='training',\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        validation_generator = train_datagen.flow_from_directory(\n",
        "            data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='validation',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        # If test_dir is provided, create test generator\n",
        "        test_dir = os.path.join(os.path.dirname(data_dir), 'test')\n",
        "        if os.path.exists(test_dir):\n",
        "            test_generator = test_datagen.flow_from_directory(\n",
        "                test_dir,\n",
        "                target_size=(self.img_height, self.img_width),\n",
        "                batch_size=self.batch_size,\n",
        "                class_mode='categorical',\n",
        "                shuffle=False\n",
        "            )\n",
        "        else:\n",
        "            test_generator = validation_generator\n",
        "\n",
        "        # Save class names\n",
        "        self.class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "        return train_generator, validation_generator, test_generator\n",
        "\n",
        "    def train(self, train_generator, validation_generator, epochs=15, callbacks=None):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        if callbacks is None:\n",
        "            # Define callbacks for model training\n",
        "            callbacks = [\n",
        "                tf.keras.callbacks.EarlyStopping(\n",
        "                    monitor='val_loss',\n",
        "                    patience=5,\n",
        "                    restore_best_weights=True\n",
        "                ),\n",
        "                tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                    monitor='val_loss',\n",
        "                    factor=0.2,\n",
        "                    patience=3,\n",
        "                    min_lr=0.00001\n",
        "                )\n",
        "            ]\n",
        "\n",
        "        # Start timing\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "\n",
        "        # Calculate training time\n",
        "        training_time = time.time() - start_time\n",
        "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "        self.history = history\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, test_generator):\n",
        "        \"\"\"Evaluate the model\"\"\"\n",
        "        # Evaluate the model\n",
        "        test_loss, test_accuracy = self.model.evaluate(test_generator)\n",
        "        print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"Test loss: {test_loss:.4f}\")\n",
        "\n",
        "        # Get predictions for confusion matrix\n",
        "        steps = test_generator.samples // test_generator.batch_size + 1\n",
        "        predictions = self.model.predict(test_generator, steps=steps)\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "        y_true = test_generator.classes[:len(y_pred)]  # Match length of predictions\n",
        "\n",
        "        # Print classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        report = classification_report(y_true, y_pred, target_names=self.class_names, output_dict=True)\n",
        "        print(classification_report(y_true, y_pred, target_names=self.class_names))\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.class_names, yticklabels=self.class_names)\n",
        "        plt.title(f'Confusion Matrix - {self.model_name}')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix.png')\n",
        "        plt.show()\n",
        "\n",
        "        return {\n",
        "            'accuracy': test_accuracy,\n",
        "            'loss': test_loss,\n",
        "            'classification_report': report,\n",
        "            'confusion_matrix': cm.tolist()\n",
        "        }\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"Plot training and validation accuracy and loss\"\"\"\n",
        "        acc = self.history.history['accuracy']\n",
        "        val_acc = self.history.history['val_accuracy']\n",
        "        loss = self.history.history['loss']\n",
        "        val_loss = self.history.history['val_loss']\n",
        "\n",
        "        epochs_range = range(len(acc))\n",
        "\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs_range, loss, label='Training Loss')\n",
        "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_history.png')\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the model and metadata\"\"\"\n",
        "        # Create directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)\n",
        "\n",
        "        # Save the model\n",
        "        self.model.save(filepath)\n",
        "\n",
        "        # Save class names and metadata\n",
        "        metadata = {\n",
        "            'class_names': self.class_names,\n",
        "            'img_height': self.img_height,\n",
        "            'img_width': self.img_width,\n",
        "            'model_name': self.model_name,\n",
        "            'date_created': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        }\n",
        "\n",
        "        with open(f\"{filepath}_metadata.json\", \"w\") as f:\n",
        "            json.dump(metadata, f)\n",
        "\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load a saved model and metadata\"\"\"\n",
        "        # Load the model\n",
        "        self.model = models.load_model(filepath, compile=True)\n",
        "\n",
        "        # Load metadata\n",
        "        try:\n",
        "            with open(f\"{filepath}_metadata.json\", \"r\") as f:\n",
        "                metadata = json.load(f)\n",
        "                self.class_names = metadata['class_names']\n",
        "                self.img_height = metadata['img_height']\n",
        "                self.img_width = metadata['img_width']\n",
        "                self.model_name = metadata.get('model_name', 'EfficientNet-Lite0')\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: Metadata file not found. Class names may not be available.\")\n",
        "\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "\n",
        "    def predict_image(self, image_path):\n",
        "        \"\"\"Predict the class of a single image\"\"\"\n",
        "        # Check if image exists\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"Error: Image file '{image_path}' not found.\")\n",
        "            return None\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = tf.keras.preprocessing.image.load_img(\n",
        "            image_path, target_size=(self.img_height, self.img_width)\n",
        "        )\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = tf.expand_dims(img_array, 0) / 255.0\n",
        "\n",
        "        # Make prediction\n",
        "        predictions = self.model.predict(img_array)\n",
        "        predicted_class_index = np.argmax(predictions[0])\n",
        "\n",
        "        # Check if class names are available\n",
        "        if self.class_names:\n",
        "            predicted_class = self.class_names[predicted_class_index]\n",
        "        else:\n",
        "            predicted_class = f\"Class {predicted_class_index}\"\n",
        "\n",
        "        confidence = float(predictions[0][predicted_class_index])\n",
        "\n",
        "        # Display results\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Predicted: {predicted_class} ({confidence:.2%})\")\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Create result dictionary with all classes and probabilities\n",
        "        results = {}\n",
        "        if self.class_names:\n",
        "            results = {self.class_names[i]: float(predictions[0][i]) for i in range(len(self.class_names))}\n",
        "        else:\n",
        "            results = {f\"Class {i}\": float(predictions[0][i]) for i in range(len(predictions[0]))}\n",
        "\n",
        "        return {\n",
        "            'predicted_class': predicted_class,\n",
        "            'confidence': confidence,\n",
        "            'all_probabilities': results,\n",
        "            'image_path': image_path\n",
        "        }\n",
        "\n",
        "    def predict_batch(self, image_dir):\n",
        "        \"\"\"Predict classes for all images in a directory\"\"\"\n",
        "        # Check if directory exists\n",
        "        if not os.path.exists(image_dir):\n",
        "            print(f\"Error: Directory '{image_dir}' not found.\")\n",
        "            return None\n",
        "\n",
        "        # Get all image files\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
        "        image_files = [\n",
        "            os.path.join(image_dir, f) for f in os.listdir(image_dir)\n",
        "            if os.path.splitext(f.lower())[1] in image_extensions\n",
        "        ]\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"No image files found in '{image_dir}'\")\n",
        "            return None\n",
        "\n",
        "        # Predict each image\n",
        "        results = []\n",
        "        for image_path in image_files:\n",
        "            print(f\"Predicting {os.path.basename(image_path)}...\")\n",
        "            result = self.predict_image(image_path)\n",
        "            if result:\n",
        "                results.append(result)\n",
        "\n",
        "        # Summarize results\n",
        "        print(f\"\\nPredicted {len(results)} images\")\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "5GFXBtrKqJ3T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
